4 机器学习中的搜索算法 
    在绝大多数机器学习算法中最优解是没有准确的的数学表达式的.
    因此需要最优化理论中中更具一般性的优化算法.

    4.1 梯度下降法和次梯度下降法

        凸优化最基本的算法,忘了去看<最优化计算方法>

        梯度下降法描述:
            w = 0;
            while(i++ < max_step) (可以设置梯度小于某值时停止迭代)
                w -= learning_rate * g'
            return w

        次梯度算法描述:
            w_sum = 0
            w = 0;
            while(i++ < max_step) 
                randomly pick v'(随机选取一个次梯度)
                    w -= learning_rate *v'
                    v_sum +=w'
            return v_sum/max_step
        
            因为不能保证每次都能严格的降低目标函数值,因此返回平均值会更稳定一些.(也不能设置停机准则)

            应用: Lasso回归
                次梯度 = 2/m * (X.T.dot(w) - y) + learning_rate * v(任意一个次梯度)