2.1 基本概念：

    2.1.1 特征组：
        在监督学习中，将每个对象的n个特征构成的向量成为该对象的特征组。

    2.1.2 标签：
        在回归问题中，训练数据含有一个标签范围（例如：0~100）；
        在分类问题中，训练数据含有一个标签向量。

    在监督学习中，有两个重要的假设：
        对象（特征组）不是无规律出现的，而是服从一定的概率分布。
        标签也不是无规律的，而是服从对象特征组决定的概率分布。

    2.1.3 特征分布：
        监督学习假定特征组是由一个样本空间（特征空间）X上的概率分布D生成的。称D为特征分布。

    2.1.4 标签分布：
        监督学习假定存在一个由x（特征空间X的一个样本）决定标签空间Y上的概率分布Dx，使x对应的
        标签y服从Dx。称Dx为标签分布。
    
    2.1.5 模型：
        X（样本空间）-> Y（标签空间）的映射集合称为模型空间Q。
        其中的任意一个映射称为一个模型。
        记作h(x)。
    
    2.1.6  监督式学习的任务：
        给定样本空间X，标签空间Y，未知特征分布D和标签分布Dx。计算模型X->Y，给定任意特征值x，
        对y进行预测。
    
    2.1.7 损失函数：
        损失函数是Y*Y（标签空间的乘）映射到正实数的函数，并且要求有如下性质：
                loss（y（true），y（predict））= 0
            其中第一个参数是真实标签，第二个参数是预测标签。
        损失函数度量了真实值和预测值的误差。

        例子：
            0-1损失函数：
                loss(y, z) = 0 (y == z)
                loss(y, z) = 1 (y != z)
            平方损失函数：
                loss(y, z) = (y - z)^2 

    2.1.8 风险函数（期望损失）：
        损失函数的期望。
        度量模型的好坏。

    2.1.9 平均损失：
        T = {(x1,y1),(x2,y2),(x3,y3)...} (独立同分布)
        在测试数据集T使用计算好的模型h(X)计算损失函数的平均值，当测试数据足够大是，平均损失可
        以良好的近似期望损失。
        因此，监督式学习普遍采用计算测试数据的平均损失的方式来度量模型的好坏。

2.2 经验损失最小化构架：
    在理想的情况下，一个监督式学习算法应该选择期望损失最小的模型。
    但是由于特征分布和标签分布未知，不能直接计算出期望损失。
    由此，采用类似2.1.9的方法近似期望损失。

    2.2.1 经验损失：
        S = {(x1,y1),(x2,y2),(x3,y3)...} (独立同分布)
        在训练数据集S中计算的平均损失称为经验损失。

    无约束经验损失最小化构架：
        给定X（特征组），Y（标签），Q（模型空间），和损失函数loss()。
        输入：S （训练数据集）
        输出：模型hs() = minloss(h) (使经验损失最小的模型)

    2.2.2 模型假设：
        模型空间Q的任意一个子集H都成为一个模型假设。



    




